{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0faf703e",
   "metadata": {},
   "source": [
    "# Install packages\n",
    "Please install all any needed packages here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812e4f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy matplotlib pandas\n",
    "%pip install torch\n",
    "%pip install torch-geometric\n",
    "%pip install torch-scatter \n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1edccc",
   "metadata": {},
   "source": [
    "# Import packages\n",
    "\n",
    "Please import all the needed packages here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aef436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "from torch_geometric.data import Dataset\n",
    "from torch_geometric.data import Data\n",
    "from os import listdir\n",
    "import json\n",
    "from os.path import isfile\n",
    "from random import sample\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_sparse import spspmm\n",
    "\n",
    "from torch_geometric.nn import GCNConv, TopKPooling, SAGEConv, GraphConv, GENConv\n",
    "from torch_geometric.utils import (\n",
    "    add_self_loops,\n",
    "    remove_self_loops,\n",
    "    sort_edge_index,\n",
    ")\n",
    "from torch_geometric.utils.repeat import repeat\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "from torch.nn import Sequential as Seq, Linear, SiLU,Tanh,ReLU\n",
    "from torch import sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eadcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(10)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842ef510",
   "metadata": {},
   "source": [
    "# Graph data creation\n",
    "\n",
    "This section creates the graph data using the Data function of pytorch geometric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a4955e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_graph_data(source_dir, sim, fake_perc):\n",
    "    \n",
    "    \"\"\"Loading the data from the source directory and returns the data\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    source_dir : source directory which contains the original graph data, with the name format 'run_{sim}'.\n",
    "    sim : simulation/run number, to identify different simulations, int\n",
    "    fake_perc : % of augmented edges\n",
    "    Ouput\n",
    "    ------\n",
    "    data - Pytorch geometric Data object\n",
    "       \n",
    "    \"\"\" \n",
    "    \n",
    "    data = torch.load(osp.join('{}/run_{}.pt'.format(source_dir,sim)))\n",
    "    \n",
    "    \n",
    "    #DO THE REST OF THE PROCESSING BASED ON YOUR DATA!!\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db23c119",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataset(Dataset):\n",
    "    \n",
    "    \"\"\"\n",
    "    Class to create custom graph dataset compatible for EAGNN\n",
    "    \n",
    "    Every graph data generated using this class contains graph of Data object.\n",
    "    \n",
    "    \"\"\" \n",
    "    \n",
    "    def __init__(self, root, source_dir, sim_list, test=False, transform=None, pre_transform=None):\n",
    "        \n",
    "        self.root = root # root directory where procssed data is stored\n",
    "        self.sims = sim_list # list of simulation numbers (different for train and test data)\n",
    "        self.test = test # flag to identify test data\n",
    "        self.source_dir = source_dir # source directory for raw data\n",
    "        \n",
    "        super(GraphDataset, self).__init__(root, transform, pre_transform)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return []\n",
    "    \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return []\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "    \n",
    "    def len(self):\n",
    "        return len(self.sims)\n",
    "    \n",
    "    def process(self):\n",
    "        i = 0\n",
    "        \n",
    "        for i in range(len(self.sims)):\n",
    "            print(\"processing simulation {}!\".format(i))\n",
    "            data = process_graph_data(self.source_dir, self.sims[i])\n",
    "            \n",
    "            if(self.test):\n",
    "                torch.save(data, osp.join(self.root, 'processed/test_run_{}.pt'.format(i)))\n",
    "                \n",
    "            else:\n",
    "                torch.save(data, osp.join(self.root, 'processed/run_{}.pt'.format(i)))\n",
    "\n",
    "    def get(self,idx):\n",
    "        \n",
    "        if(self.test):\n",
    "            i = idx \n",
    "            data = torch.load(osp.join(self.root, 'processed/test_run_{}.pt'.format(i)))\n",
    "            \n",
    "        else:\n",
    "            i = idx \n",
    "            data = torch.load(osp.join(self.root, 'processed/run_{}.pt'.format(i)))\n",
    "            \n",
    "        return data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb5a9eb",
   "metadata": {},
   "source": [
    "# Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b70e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the list of simulation numbers from the dataset\n",
    "### change this based on your data!!!\n",
    "mypath = 'dataset/'\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "file_nums=[]\n",
    "for file in onlyfiles:\n",
    "    file_nums.append(int(file.split('_')[1]))\n",
    "file_nums = np.unique(np.array(file_nums)) \n",
    "\n",
    "# defining the root and source directory\n",
    "# root directory/processed is the folder where the processed graph data is stored\n",
    "# source directory contains the raw graph data\n",
    "root_dir = \"dataset/\"\n",
    "source_dir = \"dataset\"\n",
    "\n",
    "# 500 simulations are used for training and 300 for testing\n",
    "# you can changes these numbers\n",
    "train_list = file_nums[:500]\n",
    "val_list = file_nums[500:]\n",
    "\n",
    "#change batch size and percentage of fake edges, if needed\n",
    "batch_size = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61f152e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing training and validation datasets\n",
    "train_dataset = GraphDataset(root_dir, source_dir, train_list, test=False)\n",
    "val_dataset = GraphDataset(root_dir, source_dir, val_list, test=True)\n",
    "\n",
    "## Defining the data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f7e7f9",
   "metadata": {},
   "source": [
    "# GNN Model Architecture\n",
    "\n",
    "Next section contains the functions and classes which Multi Graph Neural Network. It uses the same architecture as Graph UNet and hence the same function is used for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a12410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_sparse import spspmm\n",
    "\n",
    "from torch_geometric.nn import GCNConv, TopKPooling, SAGEConv, GraphConv, GENConv\n",
    "from torch_geometric.utils import (\n",
    "    add_self_loops,\n",
    "    remove_self_loops,\n",
    "    sort_edge_index,\n",
    ")\n",
    "from torch_geometric.utils.repeat import repeat\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "from torch.nn import Sequential as Seq, Linear, SiLU,Tanh,ReLU\n",
    "from torch import sin\n",
    "\n",
    "class GraphUNet(torch.nn.Module):\n",
    "    r\"\"\"The Graph U-Net model from the `\"Graph U-Nets\"\n",
    "    <https://arxiv.org/abs/1905.05178>`_ paper which implements a U-Net like\n",
    "    architecture with graph pooling and unpooling operations.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Size of each input sample.\n",
    "        hidden_channels (int): Size of each hidden sample.\n",
    "        out_channels (int): Size of each output sample.\n",
    "        depth (int): The depth of the U-Net architecture.\n",
    "        pool_ratios (float or [float], optional): Graph pooling ratio for each\n",
    "            depth. (default: :obj:`0.5`)\n",
    "        sum_res (bool, optional): If set to :obj:`False`, will use\n",
    "            concatenation for integration of skip connections instead\n",
    "            summation. (default: :obj:`True`)\n",
    "        act (torch.nn.functional, optional): The nonlinearity to use.\n",
    "            (default: :obj:`torch.nn.functional.relu`)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, depth,\n",
    "                 pool_ratios=0.4, sum_res=True, act=F.relu):\n",
    "        super().__init__()\n",
    "        assert depth >= 1\n",
    "        self.in_channels = in_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.depth = depth\n",
    "        self.pool_ratios = repeat(pool_ratios, depth)\n",
    "        self.act = act\n",
    "        self.sum_res = sum_res\n",
    "        self.p = 0.1 #dropout\n",
    "        channels = hidden_channels\n",
    "        \n",
    "        #encoder\n",
    "        self.mlp_encode_disp = Seq(Linear(in_channels, 64),\n",
    "                       ReLU(), \n",
    "                       Linear(64, channels))\n",
    "\n",
    "        self.down_convs = torch.nn.ModuleList()\n",
    "        self.pools = torch.nn.ModuleList()\n",
    "        self.down_convs.append(SAGEConv(channels, channels))\n",
    "        \n",
    "        for i in range(depth):\n",
    "            self.pools.append(TopKPooling(channels, self.pool_ratios[i]))\n",
    "            self.down_convs.append(SAGEConv(channels, channels))\n",
    "\n",
    "        in_channels = channels if sum_res else 2 * channels\n",
    "\n",
    "        self.up_convs = torch.nn.ModuleList()\n",
    "        for i in range(depth - 1):\n",
    "            self.up_convs.append(SAGEConv(in_channels, channels))\n",
    "        self.up_convs.append(SAGEConv(in_channels, channels))\n",
    "        \n",
    "        #decoder\n",
    "        self.mlp_decode_disp = Seq(Linear(channels, 64),\n",
    "                       ReLU(),\n",
    "                       Linear(64, out_channels))\n",
    "        \n",
    "        self.transformer = Seq(Linear(channels, channels),\n",
    "                       ReLU(),\n",
    "                       Linear(channels, channels))\n",
    "        \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.down_convs:\n",
    "            conv.reset_parameters()\n",
    "        for pool in self.pools:\n",
    "            pool.reset_parameters()\n",
    "        for conv in self.up_convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, batch=None):\n",
    "        \n",
    "        if batch is None:\n",
    "            batch = edge_index.new_zeros(x.size(0))\n",
    "            \n",
    "        edge_weight = x.new_ones(edge_index.size(1))\n",
    "        \n",
    "        x = self.mlp_encode_disp(x)\n",
    "        \n",
    "        x = F.dropout(x, p = self.p, training=self.training)\n",
    "        \n",
    "        #downsampling steps\n",
    "        x = self.down_convs[0](x, edge_index)\n",
    "        x = self.act(x)\n",
    "        x = x + self.transformer(x)\n",
    "        \n",
    "        xs = [x]\n",
    "        edge_indices = [edge_index]\n",
    "        edge_weights = [edge_weight]\n",
    "        perms = []\n",
    "\n",
    "        for i in range(1, self.depth + 1):\n",
    "            edge_index, edge_weight = self.add_edges(edge_index, edge_weight, batch)\n",
    "            x, edge_index, edge_weight, batch, perm, _ = self.pools[i - 1](\n",
    "                x, edge_index, edge_weight, batch)\n",
    "            \n",
    "            x = self.down_convs[i](x, edge_index)\n",
    "            x = self.act(x)\n",
    "            x = x + self.transformer(x)\n",
    "            x = F.dropout(x, p = self.p, training=self.training)\n",
    "            \n",
    "            if i < self.depth:\n",
    "                xs += [x]\n",
    "                edge_indices += [edge_index]\n",
    "                edge_weights += [edge_weight]\n",
    "            perms += [perm]\n",
    "        \n",
    "        #upsampling steps\n",
    "        for i in range(self.depth):\n",
    "            j = self.depth - 1 - i\n",
    "            res = xs[j]\n",
    "            edge_index = edge_indices[j]\n",
    "            edge_weight = edge_weights[j]\n",
    "            perm = perms[j]\n",
    "\n",
    "            up = torch.zeros_like(res)\n",
    "            up[perm] = x\n",
    "            \n",
    "            x = res + up if self.sum_res else torch.cat((res, up), dim=-1)\n",
    "\n",
    "            x = self.up_convs[i](x, edge_index)\n",
    "            x = self.act(x) if i < self.depth - 1 else x\n",
    "            x = x + self.transformer(x)\n",
    "            x = F.dropout(x, p = self.p, training=self.training)\n",
    "            \n",
    "        x = self.up_convs[-1](x, edge_index)\n",
    "        x = self.act(x) if i < self.depth - 1 else x\n",
    "        x = x + self.transformer(x)\n",
    "        \n",
    "        #decoder\n",
    "        x = self.mlp_decode_disp(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "    def augment_adj(self, edge_index, edge_weight, num_nodes):\n",
    "        edge_index, edge_weight = remove_self_loops(edge_index, edge_weight)\n",
    "        edge_index, edge_weight = add_self_loops(edge_index, edge_weight,\n",
    "                                                 num_nodes=num_nodes)\n",
    "        edge_index, edge_weight = sort_edge_index(edge_index, edge_weight,\n",
    "                                                  num_nodes)\n",
    "        edge_index, edge_weight = spspmm(edge_index, edge_weight, edge_index,\n",
    "                                         edge_weight, num_nodes, num_nodes,\n",
    "                                         num_nodes)\n",
    "        edge_index, edge_weight = remove_self_loops(edge_index, edge_weight)\n",
    "        return edge_index, edge_weight\n",
    "\n",
    "    #function for adding edges to nodes upto 3 hops away for better connectivity after pooling\n",
    "    def add_edges(self, edge_index, edge_weight, batch):\n",
    "        A = to_dense_adj(edge_index, edge_attr=edge_weight, batch=batch)\n",
    "        B=torch.matmul(A,A)\n",
    "        B=B/(torch.sum(B,1)+0.001)\n",
    "        B=torch.matmul(B,A)\n",
    "        edge_index, edge_weight = dense_to_sparse(B)\n",
    "        return edge_index, edge_weight\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
    "                f'{self.hidden_channels}, {self.out_channels}, '\n",
    "                f'depth={self.depth}, pool_ratios={self.pool_ratios})')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4b825a",
   "metadata": {},
   "source": [
    "# Model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99c690d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(data_loader, loss_all, device, scale):\n",
    "    \"\"\"Training the GNN model\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    data_loader : Data loader object from pytorch geometric, it contains all the graphs for training\n",
    "    loss_all : loss value, Tensor float\n",
    "    device : GPU/CPU\n",
    "    scale : if True, scaling is done on node and edge attributes as well as the target, boolean\n",
    "    \n",
    "    Ouput\n",
    "    ------\n",
    "    loss_all : loss value after a single epoch, Tensor float\n",
    "       \n",
    "    \"\"\" \n",
    "    model.train()\n",
    "    for data in data_loader:\n",
    "        # get the predicted outputs\n",
    "        out = model(data, device, scale)\n",
    "        \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        y = data[0].y.reshape(-1,1)\n",
    "            \n",
    "        # loss calculation\n",
    "        loss_calc = loss(out.reshape(-1,1), y.reshape(-1,1)) \n",
    "        loss_calc.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        my_lr_scheduler.step()\n",
    "        \n",
    "    return loss_all\n",
    "\n",
    "\n",
    "def model_eval(data_loader, device, scale):\n",
    "    \"\"\"Evaluating the GNN model\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    data_loader : Data loader object from pytorch geometric, it contains all the graphs for training\n",
    "    device : GPU/CPU\n",
    "    scale : if True, scaling is done on node and edge attributes as well as the target, boolean\n",
    "    \n",
    "    Ouput\n",
    "    ------\n",
    "    l2_err : relative L2 error for the predictions in the graph, float\n",
    "       \n",
    "    \"\"\" \n",
    "    model.eval()\n",
    "    \n",
    "    predictions = []\n",
    "    labels = []\n",
    "    \n",
    "    for data in data_loader:\n",
    "                \n",
    "        #getting the prediction from just the fine graph\n",
    "        pred = model(data, device, scale)\n",
    "        \n",
    "        pred = pred.detach().cpu().numpy().reshape(-1,1)\n",
    "            \n",
    "        label = data.y.detach().cpu().numpy().reshape(-1,1)\n",
    "        predictions.append(pred)\n",
    "        labels.append(label)\n",
    "        \n",
    "    predictions = np.vstack(predictions)\n",
    "    labels = np.vstack(labels)\n",
    "    \n",
    "    # calculation of relative L2 error\n",
    "    diff_norm = np.linalg.norm(predictions - labels, ord=2)\n",
    "    y_norm = np.linalg.norm(labels, ord=2)\n",
    "    l2_err = np.mean(diff_norm / y_norm)\n",
    "\n",
    "    return l2_err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dec07f",
   "metadata": {},
   "source": [
    "### CHANGE TRAINING AND MODEL PARAMETERS HERE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f79605",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TRAINING HYPERPARAMETERS\n",
    "n_epochs = 1000\n",
    "batch_size = 2\n",
    "lr = 0.001\n",
    "weight_decay=1e-6\n",
    "\n",
    "# MODEL PARAMETERS\n",
    "# change these based on your data\n",
    "in_channels = 14\n",
    "hidden_channels=128\n",
    "out_channels=2\n",
    "depth=3\n",
    "pool_ratios=0.6\n",
    "\n",
    "# DIRECTORIES TO STORE RESULTS\n",
    "result_dir = 'results'\n",
    "model_dir = 'models'\n",
    "loss_dir = 'losses'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117a0c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = GraphUNet(in_channels=in_channels, hidden_channels=hidden_channels, \n",
    "                  out_channels=out_channels, depth=depth, pool_ratios=pool_ratios).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.99, 0.999), weight_decay=weight_decay)\n",
    "my_lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=n_epochs, eta_min=1e-8)\n",
    "\n",
    "loss = torch.nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c8c092",
   "metadata": {},
   "source": [
    "### MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50f997e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## model training\n",
    "epoch_list = []\n",
    "train_l2_err = []\n",
    "val_l2_err = []\n",
    "\n",
    "print('Training started...')\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    loss_all = 0\n",
    "    loss_all = model_train(train_loader, loss_all, device)\n",
    "    if(epoch%10==0):\n",
    "        epoch_list.append(epoch)\n",
    "        l2_err = model_eval(train_loader, device)\n",
    "        train_l2_err.append(l2_err)\n",
    "        l2_err = model_eval(val_loader, device)\n",
    "        val_l2_err.append(l2_err)\n",
    "        print('epoch: ', epoch, 'train error: ', train_l2_err[-1], 'val error: ', val_l2_err[-1])\n",
    "        print()\n",
    "\n",
    "        # saving the model\n",
    "        torch.save({\n",
    "            'epoch':epoch,\n",
    "            'model_state_dict':model.state_dict(),\n",
    "            'optimizer_state_dict':optimizer.state_dict(),\n",
    "        }, result_dir + '/' + model_dir + '/model_mgnn.pt')\n",
    "        \n",
    "        # saving the loss results\n",
    "        np.savetxt(result_dir + '/' + loss_dir + '/train_l2_err.txt', train_l2_err)\n",
    "        np.savetxt(result_dir + '/' + loss_dir + '/val_l2_err.txt', val_l2_err)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
